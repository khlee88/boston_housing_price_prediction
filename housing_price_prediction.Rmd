---
title: "Housing Price Prediction"
output:
  html_notebook:
    highlight: tango
    number_sections: yes
    theme: cerulean
    toc: yes
---
<hr>

```{r}
library(data.table)
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)

library(Metrics)
library(xgboost)
library(glmnet)
library(ridge)
library(MASS)
library(car)
```

# Load housing data
```{r}
columns = c('CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 
           'RAD', 'TAX', 'PTRATIO', 'Bk', 'LSTAT', 'MEDV')
dt <- fread('housing.data') %>% setnames(columns)
```

# Data structure & summary
각 피처의 속성과 summary를 통해 기초 통계 및 널값 여부를 확인합니다. <br>
housing 데이터에 특이한 사항은 없는 것으로 보입니다. 
```{r}
str(dt)
```
```{r}
summary(dt)
```

# Feature distribution
각 피처를 히스토그램으로 시각화하여 분포를 확인합니다. <br>
CRIM, ZN, DIS, Bk, AGE 피처는 데이터가 한쪽으로 쏠려있는 분포를 가지고 있습니다. 이는 선형 회귀모델에서 목표변수에 많은 정보를 주지 못하기 때문에 영향이 없는 변수가 될 수 있습니다. 가능하면 변수를 적절히 변환하여 사용하는 것을 고려해 봐야 할 것 같습니다. <br>
CHAS는 0과 1의 이진 변수이고 그 외 다른 변수들은 이상치 등 특이사항이 없는 것으로 보입니다.
```{r}
viz_dt <- gather(dt, feat, value) %>% data.table()
viz_dt[, feat:=factor(feat, levels=columns)]
ggplot(viz_dt, aes(x=value)) + 
  geom_histogram(aes(y=..density..), bins = 30, colour="black", fill="white") + 
  geom_density(alpha=.2, fill="#FF6666") +
  facet_wrap(.~feat, scales = "free")
```

# Split train & test data
8:2의 비율로 학습셋과 테스트셋을 나눕니다.
```{r}
set.seed(1050)
trn_idx <- sample(nrow(dt), nrow(dt)*0.8)

trn_dt <- dt[trn_idx, ]
tst_dt <- dt[-trn_idx, ]
```

# Feature scaling
CRIM, ZN, DIS 변수는 위 분포에서 왼쪽으로 쏠려있는 롱테일 분포를 가지고 있습니다. log scaling을 수행합니다. <br>
ZN은 0 값이 많으므로 scailing 후 0 값의 분포는 그대로 유지되어 큰 변화가 없어 보입니다. <br>
CRIM과 DIS는 변환 후 분포가 펴진 것을 확인할 수 있습니다.
```{r}
viz_dt[feat %in% c('CRIM', 'DIS'), value_s:=log(value)]
viz_dt[feat=='ZN', value_s:=log1p(value)]

ggplot(viz_dt[feat %in% c('CRIM', 'ZN', 'DIS')], aes(x=value_s)) + 
  geom_histogram(aes(y=..density..), bins = 30, colour="black", fill="white") + 
  geom_density(alpha=.2, fill="#FF6666") +
  facet_wrap(.~feat, scales = "free")
```

3개 변수의 MEDV 값과의 상관관계를 scale 전과 후로 비교해 보면, scale 후 상관관계가 높아진 것을 확인할 수 있습니다.
```{r}
cat("CRIM origin: ", cor(trn_dt$CRIM, trn_dt$MEDV),
"CRIM scaled: ", cor(log(trn_dt$CRIM), trn_dt$MEDV), "\n")

cat("ZN origin: ", cor(trn_dt$ZN, trn_dt$MEDV),
"ZN scaled: ", cor(log1p(trn_dt$ZN), trn_dt$MEDV), "\n")

cat("DIS origin: ", cor(trn_dt$DIS, trn_dt$MEDV),
"DIS scaled: ", cor(log(trn_dt$DIS), trn_dt$MEDV))
```

AGE와 Bk 변수는 정규화 변환을 수행하고 나머지는 적절한 비율로 조정합니다. 
```{r}
## 테스트 데이터에서 동일한 변환을 위해, 
## 정규변환 피처의 학습데이터 평균과 분산 값을 유지 합니다.
age_attr <- c(mean(trn_dt$AGE), sd(trn_dt$AGE))
bk_attr <- c(mean(trn_dt$Bk), sd(trn_dt$Bk))
feat_attr <- list('age'=age_attr, "bk"=bk_attr)

feat_scaling <- function(dt, feat_attr) {
  dt$CRIM <- log(dt$CRIM)
  dt$ZN   <- log1p(dt$ZN)
  dt$DIS  <- log(dt$DIS)
  dt$AGE <- scale(dt$AGE, feat_attr$age[1], feat_attr$age[2])
  dt$Bk  <- scale(dt$Bk, feat_attr$bk[1], feat_attr$bk[2])
  dt$INDUS   <- dt$INDUS/10
  dt$RAD     <- dt$RAD/10
  dt$PTRATIO <- dt$PTRATIO/10
  dt$LSTAT   <- dt$LSTAT/10
  dt$TAX     <- dt$TAX/100
  return(dt)
}
```

학습, 테스트 데이터를 scaling 합니다.
```{r}
trn_sdt <- feat_scaling(trn_dt, feat_attr)
tst_sdt <- feat_scaling(tst_dt, feat_attr)
```

# Correlation
각 피처와 목표변수 MEDV의 상관관계를 확인합니다. <br>
RM이 약 0.69로 가장 높은 양의 상관관계를 보이고 LSTAT가 약 -0.75로 가장 높은 음의 상관관계를 보입니다. <br>
주거당 평균 방수가 높을수록 그리고 인구 밀집도가 높은 곳일수록 집값이 높아진다고 해석할 수 있고, 일반적인 상식에 부합합니다. <br>
CRIM(범죄율이 높은 곳), INDUS(상업화가 덜 된 곳), NOX(공기가 안 좋은 곳), AGE(연령대가 높은 곳)은 집값과 약한 음의 상관관계를 보이고, 이는 상식적으로 생각됩니다. <br>
PTRATIO는 학생교사의 비율로 학생교사가 높다는 것은 정규교사 부족한 곳이기 때문이라고 생각합니다. 정규교사는 중상류층에 속한다고 생각하고 이러한 인구가 부족한 것은 상대적으로 하류층 비율이 높은 마을이라 생각됩니다. 이러한 이유로 학생교사의 비율은 집값에 음의 상관관계를 미칠 수 있다고 생각됩니다. <br>
RAD(고속도로 접근용이 지수)는 고속도로에 접근이 용이한 곳의 집값이 높을 것이라고 생각되는데 음의 상관관계로 나타난 것이 특이해 보입니다. <br>
ZN(넓은 주거지 비율), DIS(고용센터와의 가중 거리), CHAS(강변 지역), Bk(흑인 비율)는 집값에 약한 양의 상관관계를 보이고, Bk가 양의 상관관계를 보이는 것이 특이한 점으로 보입니다. 
```{r}
corr <- cor(as.matrix(trn_sdt))
corr[nrow(corr), 1:nrow(corr)]
```

# multicollinearity
피처들 간의 다중공선성을 확인합니다. <br>
선형 모델에서 피처가 많을수록 피처 간 공선성 문제가 생길 수 있고, 결과적으로 정보의 분산으로 인해 모델의 성능을 저해하는 요인으로 작용합니다. <br>
일반적으로 다중공선성 검증은 절대 상관관계가 0.8 이상이거나, VIF(variance inflation factor) 값이 10 이상일 때 다중공선성을 의심할 수 있습니다. <br>
<br>
상관계수로는 (CRIM, RAD, TAX)와 (DIS, NOX)의 공선성을 의심해 볼 수 있습니다.
```{r}
feat_num <- nrow(corr)
corr2 <- which(abs(corr)>0.8)
corr3 <- (corr2-1) %/% feat_num + 1
corr4 <- corr2 - (corr3-1)*feat_num
corr5 <- colnames(corr)
corr6 <- data.table(x=corr3, y=corr4, x1=corr5[corr3], y1=corr5[corr4], relation=corr[which(abs(corr)>0.8)])
corr7 <- corr6[x!=y, ][order(x1), ]
corr7
```

VIF 값으로는 공선성으로 의심되는 변수가 없지만, (RAD, TAX)가 10에 가깝게 나타납니다.
```{r}
lmfit <- lm(MEDV ~ . , data = trn_sdt)
vif <- vif(lmfit)
vif
```

최종 공선성으로 의심되어, 제거 해야 할 변수로 RAD, TAX를 선택합니다.
```{r}
mcorr <- c('RAD', 'TAX')
```

# Evaluation Metrics
평가 지표는 RMSE, MAE, MAPE 3가지 지표로 비교합니다.
regression에서 MAPE는 목표값으로부터 예측값이 얼마 벗어났는지 percentage error를 확인할 수 있기 때문에, 모델의 성능(에러율)을 직관적으로 알 수 있습니다.
$$RMSE = \sqrt \frac {\sum\limits_{i = 1}^N {{{(x_i - \hat x_i)}^2}} } N$$
$$MAE = \frac{{\sum\limits_{i = 1}^N {\left| {x_i - \hat x_i} \right|} }} N$$
$$MAPE = \frac{100}{N}\sum\limits_{i = 1}^N {\left| {\frac{{x_i - {{\hat x}_i}}}{x_i}} \right|} $$

# Model Train
학습 모델은 Linear, Ridge, Lasso regression에 대해 학습을 수행하고 성능을 비교합니다. <br>
각 모델은 모든 변수를 사용한 경우와 공선성 변수를 제거한 경우 그리고 Linear 모델은 stepwise 변수 선택한 경우를 비교합니다. 마지막으로 비선형성을 고려하여 XGBoost 모델과 비교합니다. 총 비교 모델은 8개로 다음과 같습니다. <br>

* Linear regression
  * 모든 변수
  * stepwise 변수 선택
  * 공선성 제거 변수
* Ridge regression
  * 모든 변수
  * 공선성 제거 변수
* Lasso regression
  * 모든 변수
  * 공선성 제거 변수
* xgboost

```{r}
## Linear - 모든 변수
m1 <- lm(MEDV~., data=trn_sdt)
## Linear - stepwise
m2 <- stepAIC(m1, direction="both", trace=0)
## Linear - 공선성 제거 변수
m3 <- lm(MEDV~., data=trn_sdt[, -mcorr, with=FALSE])
## Ridge - 모든 변수
m4 <- linearRidge(MEDV~., data = trn_sdt)
## Ridge - 공선성 제거 변수
m5 <- linearRidge(MEDV~., data=trn_sdt[, -mcorr, with=FALSE])
## Lasso - 모든 변수
cv.out <- cv.glmnet(as.matrix(trn_sdt[, -"MEDV"]), trn_sdt$MEDV, alpha = 1)
m6 <- glmnet(as.matrix(trn_sdt[, -"MEDV"]), 
             trn_sdt$MEDV, alpha = 1, lambda = cv.out$lambda.min)
## Lasso - 공선성 제거 변수
cv.out <- cv.glmnet(as.matrix(trn_sdt[, -c("MEDV", mcorr), with=FALSE]),
                    trn_sdt$MEDV, alpha = 1)
m7 <- glmnet(as.matrix(trn_sdt[, -c("MEDV", mcorr), with=FALSE]), 
             trn_sdt$MEDV, alpha = 1, lambda = cv.out$lambda.min)
## xgboost
m8 <- xgboost(data = as.matrix(trn_sdt[, -"MEDV"]), label = trn_sdt$MEDV, booster='gbtree',
              objective = "reg:linear", nround = 15)
```

# Prediction & Evaluation
```{r}
y1 <- predict(m1, tst_sdt)
y2 <- predict(m2, tst_sdt)
y3 <- predict(m3, tst_sdt[, -mcorr, with=FALSE])
y4 <- predict(m4, tst_sdt)
y5 <- predict(m5, tst_sdt[, -mcorr, with=FALSE])
y6 <- predict(m6, as.matrix(tst_sdt[, -"MEDV"]))
y7 <- predict(m7, as.matrix(tst_sdt[, -c("MEDV", mcorr), with=FALSE]))
y8 <- predict(m8, as.matrix(tst_sdt[, -"MEDV"]))
```

Linear regression 모델에서는 공선성 변수를 제거한 모델이 모든 변수를 사용한 모델과 변수 선택을 한 모형보다 좋은 성능을 보였습니다. 공선성 변수가 모델 성능을 저해한다는 사실을 확인할 수 있습니다. <br>
Ridge와 Lasso는 정규화를 통해 공선성 문제를 해결할 수 있다고 알려져 있습니다. 이번 문제에서는 Lasso의 성능보다 Ridge의 성능이 선형회귀 모형 중 가장 좋은 성능을 보입니다. 그리고 rmse 측면에서는 모든 변수를 사용했을 때가 mae, mape 측면에서는 공선성 변수를 제거했을 때가 조금 더 좋은 성능을 보입니다. <br>
하지만 전체 성능은 XGBoost가 선형모형보다 더 우수한 성능을 보이고 집값을 예측하는데 비선형적인 요소가 있는 것으로 보입니다.
```{r}
eval_list <- list()
for(i in 1:8) {
  rmse_ <- rmse(tst_sdt$MEDV, get(paste0("y", i)))
  mae_ <- mae(tst_sdt$MEDV, get(paste0("y", i)))
  mape_ <- mape(tst_sdt$MEDV, get(paste0("y", i)))
  eval_list[[i]] <- data.frame("model"=i, "rmse"=rmse_, "mae"=mae_, "mape"=mape_)
}

rbindlist(eval_list)
```

# Feature importance
선형모델에서 가장 성능이 좋았던 공선성 변수를 제거한 Ridge 모델(m5)과 전체 모델 중 가장 성능이 좋은 비선형 모델인 xgboost(m8)에 대한 각 모델의 피처 중요도(계수)를 확인해 봅니다. <br>
<br>
m5 모델에서 통계적으로 유의한 변수는 CHAS, NOX, RM, DIS, PTRATIO, Bk, LSTAT 입니다. scaled estimate 값을 보면, LSTAT 변수가 음의 방향으로 가장 큰 영향을 미치고 그다음으로 DIS가 그리고 RM 변수가 양의 방향으로 영향을 미치는 것을 확인할 수 있습니다. <br>
DIS 변수는 목표변수와의 상관관계가 양의 관계를 보였는데, 모델에서 음의 관계로 두 번째로 큰 영향을 미치는 점이 특이하게 보입니다.
```{r}
summary(m5)
```

xgboost(m8) 모델은 정보량(Gain)을 보면, LSTAT가 집값을 예측하는데 가장 많은 정보를 가지고, 그다음으로 RM이 많은 정보를 가진 것을 확인할 수 있습니다. 이 두 변수가 전체 변수 중 gain의 85%의 비율을 가지는 것을 보아 집값을 예측하는데 가장 중요한 요인으로 해석해 볼 수 있습니다. 
```{r}
xgb.importance(model = m8)
```

